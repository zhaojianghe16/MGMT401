{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 - Linear Regression\n",
    "\n",
    "## Dataset\n",
    "The dataset you will be using is the \"Bike Sharing\". \n",
    "\n",
    "There are two data files: \"BikeSharing_training.csv\" and \"BikeSharing_Xtest.csv\"<br/>\n",
    "Both files have the following fields, except cnt which is not available in \"BikeSharing_Xtest.csv\"\n",
    "\n",
    "Features:\n",
    "- season : season (1:winter, 2:spring, 3:summer, 4:fall)\n",
    "- mnth : month ( 1 to 12)\n",
    "- hr : hour (0 to 23)\n",
    "- holiday : weather day is holiday or not\n",
    "- weekday : day of the week\n",
    "- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n",
    "+ weathersit :\n",
    "- 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\n",
    "- atemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)\n",
    "- hum: Normalized humidity. The values are divided to 100 (max)\n",
    "- windspeed: Normalized wind speed. The values are divided to 67 (max)\n",
    "\n",
    "Target:\n",
    "- cnt: count of total rental bikes\n",
    "\n",
    "\n",
    "Training dataset, \"BikeSharing_training.csv\", contains 300 rows and 12 columns. This is the training set containing both of the features and the target.<br/>\n",
    "Test dataset, \"BikeSharing_Xtest.csv\", contains 200 rows and 11 columns. This is the test set which only contains the features.<br/>\n",
    "\n",
    "Your goal is to predict the number of total rental bikes (cnt) based on the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training data and View the first 5 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "\n",
    "# Show the first 5 lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "We can plot a histogram of the dataframe for the features: \"temp\", \"atemp\",\"hum\",\"windspeed\" to understand the distributions of the continuous values.<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE CODE TO OBTAIN AND DISPLAY HISTOGRAMS ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q1. What can you infer from the histograms? <br/>\n",
    "Ans- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the correlation matrix to get an understanding of the correlation between cnt and the other features.<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer the following questions:<br/>\n",
    "\n",
    "##### Q2. Why is the diagonal made up of 1's in the correlation matrix?<br/>\n",
    "Ans - \n",
    "\n",
    "##### Q3. Why is the matrix symmetric along diagonal?<br/>\n",
    "Ans - \n",
    "\n",
    "##### Q4. Looking at the correlation matrix, if you have to choose one predictor for a simple linear regression model with cnt as the outcome, which one would you choose and why? <br/>\n",
    "Ans - \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature standardization makes the values of each feature in the data have zero-mean and unit-variance. This method is widely used for normalization in many machine learning algorithms. The general method of calculation is to determine the distribution mean and standard deviation for each feature. Next we subtract the mean from each feature. Then we divide the values of each feature by its standard deviation.\n",
    "\n",
    "$x'$ = ($x$ - $\\bar{x}$)/$\\sigma$ \n",
    "\n",
    "where $x$ is the original feature vector,\n",
    "$\\bar{x}$ is the mean of the feature vector and\n",
    "$\\sigma$ is its standard deviation.\n",
    "\n",
    "This is also called Z-score Normalization. \n",
    "\n",
    "Perform Z-score Normalization on \"temp\", \"atemp\",\"hum\",\"windspeed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q5. What are the advantages and disadvantages of using Z-score Normalization?<br/>\n",
    "Ans-\n",
    "\n",
    "##### Q6. In this dataset, do you need to use the Z-score Normalization? Explain.<br/>\n",
    "Ans- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"temp\", \"atemp\",\"hum\" and \"windspeed\" are continuous values whereas the others contain discrete values. E.g. \"mnth\" can only take on the integers from 1 to 12. We need to perform one-hot encoding on discrete values for it to be processed in the model. One hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction.\n",
    "\n",
    "Perform one-hot encoding on all the categorical features and print the shape of your encoded array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Print the shape of your encoded X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q7. What are the advantages and disadvantages of using One-hot encoding?<br/>\n",
    "Ans-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "In the big data era, it is highly unlikely that we are interested in the effect of a single variable on another. To simultaneously account for the effects of multiple variables, we use multiple regression (which accounts for the covariances between predictors).\n",
    "\n",
    "While the algorithmic solution to multiple regression exists, it is easier to conceptualize in terms of linear algebra. The optimal $\\hat{\\beta}$ vector that minimizes the residual sum of squares is:\n",
    "\n",
    "$\\hat{\\beta} = (X^TX)^{-1}X^Ty $\n",
    "\n",
    "\n",
    "Perform multiple linear regression on the training dataset, where the outcome is \"cnt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulding and fitting the Linear Regression model \n",
    "\n",
    "# Evaluating the Linear Regression model by computing MSE on training set\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Q8. Print the value of bhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Q9. Is there a problem of multicolinearity? Explain what you can do<br/>\n",
    "Ans- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodness of fit\n",
    "\n",
    "A model can always make predictions. But it is important to determine how good the model is.\n",
    "How do we know that our model captures the data well? When evaluating model fit, a good metric is $R^2$, which corresponds to the amount of variance explained by the model. The formula for $R^2$ is the following:\n",
    "\n",
    "$R^2$ = $1 - \\dfrac{RSS}{TSS}$<br/>\n",
    "where:<br/>\n",
    "$RSS = \\Sigma(y - \\hat{y})^2$<br/>\n",
    "$TSS = \\Sigma(y - \\bar{y})^2$<br/>\n",
    "\n",
    "$R^2$ is also one metric for comparing models against each other. It is intuitive to say that the model that explains more variation in the data is a better fit than one that explains less variation. \n",
    "\n",
    "Fill in the code for calculation of R2 score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2 score for model with \"temp\" as predictor and \"cnt\" as outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Print R2 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2 score for model with \"temp\", \"hum\" as predictors and \"cnt\" as outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Print R2 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2 score for model with  \"temp\", \"atemp\", \"hum\" as predictors and \"cnt\" as outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Print R2 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see $R^2$ is always going up as we keep adding features.\n",
    "\n",
    "This is one drawback of only using $R^2$ to evaluate your model. Adding predictors seems to always improve the predictive ability of your model, though it may not be true.\n",
    "\n",
    "That is to say, we are not necessarily interested in making a perfect prediciton of our training data. If we were, we would always use all of the predictors available. Rather, we would like to make a perfect prediction of our test data. In this case, adding all the predictors may not be a good idea due to the trade-off between bias and variance. Thus, we are interested in the most predictive features, in the hopes that we can create a simpler model that performs well in the future.\n",
    "\n",
    "This is why we consider another metric, Adjusted R2.\n",
    "The adjusted R-squared increases only if the new term improves the model more than would be expected by chance.\n",
    "\n",
    "\n",
    "$AdjustedR^2$ = $1 - \\dfrac{(1-R^2)(n-1)}{(n-k-1)}$<br/>\n",
    "where:<br/>\n",
    "n = number of samples<br/>\n",
    "k = number of features\n",
    "\n",
    "Fill in the code for calculation of adjusted R2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusted R2 score for model with \"temp\" as predictor and \"cnt\" as outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Print Adjusted R2 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusted R2 score for model with \"temp\", \"hum\" as predictors and \"cnt\" as outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Print Adjusted R2 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusted R2 score for model with  \"temp\", \"atemp\", \"hum\" as predictors and \"cnt\" as outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Print Adjusted R2 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross-Validation\n",
    "\n",
    "However, adjusted R2 is not enough to help us ahieve the best model, a more robust method is k-fold cross-validation.\n",
    "\n",
    "* Randomly split dataset into K equal-sized subsets, or folds\n",
    "* Treat each fold as validation set (train on all but K'th fold and test on K'th fold only)\n",
    "\n",
    "* The overall error is then the mean error over all K models.\n",
    "* Most common are 5- or 10-fold cross-validation\n",
    "\n",
    "Please implement a 5-fold cross-validation by yourselves to find the best model in terms of Mean Square Error(MSE)\n",
    "\n",
    "**Do not use sklearn.model_selection.cross_val_score or other built-in cross-validaiton functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a function to implement 5-fold cross-validation. \n",
    "# The input: training features X, training target y.\n",
    "# The output: the average of MSE over the 5 folds.\n",
    "\n",
    "def cross_val_mse(X, y):\n",
    "    # Write your code here\n",
    "    \n",
    "    \n",
    "    return()\n",
    "\n",
    "# By using your above function, find the best combination of features, which has the lowest averaged MSE\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best features \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your model\n",
    "Now, apply your best model to predict the target values from the test feature set \"BikeSharing_Xtest.csv\". We will grade this part based on your prediction error.\n",
    "\n",
    "Hint: Please be careful on standardization and one-hot encoding (if you use), the test set should be consistent with the training set in terms of any transformation.\n",
    "\n",
    "Hint2: You may want to modify the previous steps to make the transformation of the test set consistent with the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Output your prediction on test set as y_pred. It should be a 200 x 1 vector.\n",
    "# y_pred ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
