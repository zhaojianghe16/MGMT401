{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Exercise1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhaojianghe16/MGMT401/blob/Dev/Exercise1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FNcDX0ZZYla"
      },
      "source": [
        "# Homework 1 - Linear Regression\n",
        "\n",
        "## Dataset\n",
        "The dataset you will be using is the \"Bike Sharing\". \n",
        "\n",
        "There are two data files: \"BikeSharing_training.csv\" and \"BikeSharing_Xtest.csv\"<br/>\n",
        "Both files have the following fields, except cnt which is not available in \"BikeSharing_Xtest.csv\"\n",
        "\n",
        "Features:\n",
        "- season : season (1:winter, 2:spring, 3:summer, 4:fall)\n",
        "- mnth : month ( 1 to 12)\n",
        "- hr : hour (0 to 23)\n",
        "- holiday : weather day is holiday or not\n",
        "- weekday : day of the week\n",
        "- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n",
        "+ weathersit :\n",
        "- 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
        "- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
        "- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
        "- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
        "- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\n",
        "- atemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)\n",
        "- hum: Normalized humidity. The values are divided to 100 (max)\n",
        "- windspeed: Normalized wind speed. The values are divided to 67 (max)\n",
        "\n",
        "Target:\n",
        "- cnt: count of total rental bikes\n",
        "\n",
        "\n",
        "Training dataset, \"BikeSharing_training.csv\", contains 300 rows and 12 columns. This is the training set containing both of the features and the target.<br/>\n",
        "Test dataset, \"BikeSharing_Xtest.csv\", contains 200 rows and 11 columns. This is the test set which only contains the features.<br/>\n",
        "\n",
        "Your goal is to predict the number of total rental bikes (cnt) based on the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttpubQf2ZYlc"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vlYY8B2ZYll"
      },
      "source": [
        "Load the training data and View the first 5 lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVAHshAsZYlm",
        "outputId": "71ddd9d7-38de-4670-f649-e0223bdef3e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the data\n",
        "training_dataset= pd.read_csv('https://raw.githubusercontent.com/zhaojianghe16/Public_Save_File_Online/master/BikeSharing_training.csv')\n",
        "test_dataset = pd.read_csv('https://raw.githubusercontent.com/zhaojianghe16/Public_Save_File_Online/master/BikeSharing-Xtest.csv')\n",
        "\n",
        "\n",
        "# Show the first 5 lines\n",
        "print(training_dataset.head()) \n",
        "print(test_dataset.head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   season  mnth  hr  holiday  weekday  ...  temp   atemp   hum  windspeed  cnt\n",
            "0       1    12  16        0        5  ...  0.42  0.4242  0.47     0.1940  283\n",
            "1       4    10   9        0        0  ...  0.50  0.4848  0.55     0.4179  330\n",
            "2       3     9   1        0        0  ...  0.62  0.5606  0.88     0.0000   88\n",
            "3       3     6  22        0        3  ...  0.70  0.6364  0.42     0.1940  183\n",
            "4       3     7  12        0        1  ...  0.80  0.7424  0.52     0.1642  314\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "   season  mnth  hr  holiday  ...  temp   atemp   hum  windspeed\n",
            "0       4    11  11        1  ...  0.42  0.4242  0.41     0.0896\n",
            "1       1    12  13        0  ...  0.30  0.3030  0.49     0.1343\n",
            "2       4    11  18        0  ...  0.44  0.4394  0.67     0.1045\n",
            "3       4    10  16        0  ...  0.70  0.6515  0.54     0.2836\n",
            "4       4    12  17        0  ...  0.28  0.3182  0.30     0.0000\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMHLYs1UZYlp"
      },
      "source": [
        "## Data Exploration\n",
        "We can plot a histogram of the dataframe for the features: \"temp\", \"atemp\",\"hum\",\"windspeed\" to understand the distributions of the continuous values.<br/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTBdG3NsZYlr",
        "outputId": "1ef742e2-c605-4b37-c094-b982976ee4f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "### WRITE CODE TO OBTAIN AND DISPLAY HISTOGRAMS ###\n",
        "training_dataset[[\"temp\", \"atemp\",\"hum\",\"windspeed\"]].hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fb3ab1b5588>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fb3aad1f0f0>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fb3aacd5358>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fb3aac865c0>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVB_ikLLZYlu"
      },
      "source": [
        "##### Q1. What can you infer from the histograms? <br/>\n",
        "Ans- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpuLAZueZYlv"
      },
      "source": [
        "Compute the correlation matrix to get an understanding of the correlation between profit and different kinds of expenditure.<br/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z0EmTfxZYlv",
        "outputId": "e20de9b9-be86-4ffe-9032-b68d2cd45ee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "training_dataset.corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>season</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>season</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.795990</td>\n",
              "      <td>-0.046306</td>\n",
              "      <td>-0.057180</td>\n",
              "      <td>-0.049248</td>\n",
              "      <td>0.087355</td>\n",
              "      <td>0.097812</td>\n",
              "      <td>0.403317</td>\n",
              "      <td>0.406946</td>\n",
              "      <td>0.155086</td>\n",
              "      <td>-0.110663</td>\n",
              "      <td>0.225385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mnth</th>\n",
              "      <td>0.795990</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000608</td>\n",
              "      <td>-0.012655</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.045749</td>\n",
              "      <td>0.098688</td>\n",
              "      <td>0.270690</td>\n",
              "      <td>0.265519</td>\n",
              "      <td>0.116613</td>\n",
              "      <td>-0.005633</td>\n",
              "      <td>0.144026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hr</th>\n",
              "      <td>-0.046306</td>\n",
              "      <td>0.000608</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.104970</td>\n",
              "      <td>0.029337</td>\n",
              "      <td>-0.083801</td>\n",
              "      <td>-0.117088</td>\n",
              "      <td>0.049154</td>\n",
              "      <td>0.042834</td>\n",
              "      <td>-0.375612</td>\n",
              "      <td>0.162829</td>\n",
              "      <td>0.387503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>holiday</th>\n",
              "      <td>-0.057180</td>\n",
              "      <td>-0.012655</td>\n",
              "      <td>0.104970</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.065359</td>\n",
              "      <td>-0.216498</td>\n",
              "      <td>-0.059273</td>\n",
              "      <td>0.023122</td>\n",
              "      <td>0.020936</td>\n",
              "      <td>-0.064204</td>\n",
              "      <td>-0.043506</td>\n",
              "      <td>0.018659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weekday</th>\n",
              "      <td>-0.049248</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.029337</td>\n",
              "      <td>-0.065359</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.096844</td>\n",
              "      <td>-0.088959</td>\n",
              "      <td>-0.057797</td>\n",
              "      <td>-0.071621</td>\n",
              "      <td>-0.098027</td>\n",
              "      <td>0.073404</td>\n",
              "      <td>0.067401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>workingday</th>\n",
              "      <td>0.087355</td>\n",
              "      <td>0.045749</td>\n",
              "      <td>-0.083801</td>\n",
              "      <td>-0.216498</td>\n",
              "      <td>0.096844</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.131374</td>\n",
              "      <td>-0.007330</td>\n",
              "      <td>-0.001266</td>\n",
              "      <td>0.168470</td>\n",
              "      <td>-0.000534</td>\n",
              "      <td>-0.072353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weathersit</th>\n",
              "      <td>0.097812</td>\n",
              "      <td>0.098688</td>\n",
              "      <td>-0.117088</td>\n",
              "      <td>-0.059273</td>\n",
              "      <td>-0.088959</td>\n",
              "      <td>0.131374</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.014367</td>\n",
              "      <td>-0.018496</td>\n",
              "      <td>0.403589</td>\n",
              "      <td>-0.047412</td>\n",
              "      <td>-0.167125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>temp</th>\n",
              "      <td>0.403317</td>\n",
              "      <td>0.270690</td>\n",
              "      <td>0.049154</td>\n",
              "      <td>0.023122</td>\n",
              "      <td>-0.057797</td>\n",
              "      <td>-0.007330</td>\n",
              "      <td>-0.014367</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.992783</td>\n",
              "      <td>-0.037122</td>\n",
              "      <td>-0.096506</td>\n",
              "      <td>0.435036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>atemp</th>\n",
              "      <td>0.406946</td>\n",
              "      <td>0.265519</td>\n",
              "      <td>0.042834</td>\n",
              "      <td>0.020936</td>\n",
              "      <td>-0.071621</td>\n",
              "      <td>-0.001266</td>\n",
              "      <td>-0.018496</td>\n",
              "      <td>0.992783</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.017675</td>\n",
              "      <td>-0.126852</td>\n",
              "      <td>0.430083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hum</th>\n",
              "      <td>0.155086</td>\n",
              "      <td>0.116613</td>\n",
              "      <td>-0.375612</td>\n",
              "      <td>-0.064204</td>\n",
              "      <td>-0.098027</td>\n",
              "      <td>0.168470</td>\n",
              "      <td>0.403589</td>\n",
              "      <td>-0.037122</td>\n",
              "      <td>-0.017675</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.228720</td>\n",
              "      <td>-0.321508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>windspeed</th>\n",
              "      <td>-0.110663</td>\n",
              "      <td>-0.005633</td>\n",
              "      <td>0.162829</td>\n",
              "      <td>-0.043506</td>\n",
              "      <td>0.073404</td>\n",
              "      <td>-0.000534</td>\n",
              "      <td>-0.047412</td>\n",
              "      <td>-0.096506</td>\n",
              "      <td>-0.126852</td>\n",
              "      <td>-0.228720</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.034753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cnt</th>\n",
              "      <td>0.225385</td>\n",
              "      <td>0.144026</td>\n",
              "      <td>0.387503</td>\n",
              "      <td>0.018659</td>\n",
              "      <td>0.067401</td>\n",
              "      <td>-0.072353</td>\n",
              "      <td>-0.167125</td>\n",
              "      <td>0.435036</td>\n",
              "      <td>0.430083</td>\n",
              "      <td>-0.321508</td>\n",
              "      <td>0.034753</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              season      mnth        hr  ...       hum  windspeed       cnt\n",
              "season      1.000000  0.795990 -0.046306  ...  0.155086  -0.110663  0.225385\n",
              "mnth        0.795990  1.000000  0.000608  ...  0.116613  -0.005633  0.144026\n",
              "hr         -0.046306  0.000608  1.000000  ... -0.375612   0.162829  0.387503\n",
              "holiday    -0.057180 -0.012655  0.104970  ... -0.064204  -0.043506  0.018659\n",
              "weekday    -0.049248  0.001790  0.029337  ... -0.098027   0.073404  0.067401\n",
              "workingday  0.087355  0.045749 -0.083801  ...  0.168470  -0.000534 -0.072353\n",
              "weathersit  0.097812  0.098688 -0.117088  ...  0.403589  -0.047412 -0.167125\n",
              "temp        0.403317  0.270690  0.049154  ... -0.037122  -0.096506  0.435036\n",
              "atemp       0.406946  0.265519  0.042834  ... -0.017675  -0.126852  0.430083\n",
              "hum         0.155086  0.116613 -0.375612  ...  1.000000  -0.228720 -0.321508\n",
              "windspeed  -0.110663 -0.005633  0.162829  ... -0.228720   1.000000  0.034753\n",
              "cnt         0.225385  0.144026  0.387503  ... -0.321508   0.034753  1.000000\n",
              "\n",
              "[12 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xHMDCpLZYly"
      },
      "source": [
        "##### Answer the following questions:<br/>\n",
        "\n",
        "##### Q2. Why is the diagonal made up of 1's in the correlation matrix?<br/>\n",
        "Ans - \n",
        "\n",
        "##### Q3. Why is the matrix symmetric along diagonal?<br/>\n",
        "Ans - \n",
        "\n",
        "##### Q4. Looking at the correlation matrix, if you have to choose one predictor for a simple linear regression model with cnt as the outcome, which one would you choose and why? <br/>\n",
        "Ans - \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAcZwB6PZYlz"
      },
      "source": [
        "### Standardization of features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WW2hP_LZYlz"
      },
      "source": [
        "Feature standardization makes the values of each feature in the data have zero-mean and unit-variance. This method is widely used for normalization in many machine learning algorithms. The general method of calculation is to determine the distribution mean and standard deviation for each feature. Next we subtract the mean from each feature. Then we divide the values of each feature by its standard deviation.\n",
        "\n",
        "$x'$ = ($x$ - $\\bar{x}$)/$\\sigma$ \n",
        "\n",
        "where $x$ is the original feature vector,\n",
        "$\\bar{x}$ is the mean of the feature vector and\n",
        "$\\sigma$ is its standard deviation.\n",
        "\n",
        "This is also called Z-score Normalization. \n",
        "\n",
        "Perform Z-score Normalization on \"temp\", \"atemp\",\"hum\",\"windspeed\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As4dIIPWZYl0",
        "outputId": "c949f366-c5da-4ec9-b1fa-e2354a1421c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "feature = training_dataset[[\"temp\", \"atemp\",\"hum\",\"windspeed\"]]\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(feature)\n",
        "\n",
        "print(feature.head())\n",
        "feature=scaler.transform(feature )\n",
        "\n",
        "print(feature[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   temp   atemp   hum  windspeed\n",
            "0  0.42  0.4242  0.47     0.1940\n",
            "1  0.50  0.4848  0.55     0.4179\n",
            "2  0.62  0.5606  0.88     0.0000\n",
            "3  0.70  0.6364  0.42     0.1940\n",
            "4  0.80  0.7424  0.52     0.1642\n",
            "[[-4.07572539e-01 -3.03587659e-01 -7.90860172e-01  5.40063916e-04]\n",
            " [ 6.55705186e-03  4.47228379e-02 -3.59579915e-01  1.83266598e+00]\n",
            " [ 6.27751439e-01  4.80398344e-01  1.41945115e+00 -1.58692054e+00]\n",
            " [ 1.04188103e+00  9.16073850e-01 -1.06041033e+00  5.40063916e-04]\n",
            " [ 1.55954302e+00  1.52532983e+00 -5.21310011e-01 -2.43306977e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZCOc9KWZYl2"
      },
      "source": [
        "##### Q5. What are the advantages and disadvantages of using Z-score Normalization?<br/>\n",
        "Ans-\n",
        "\n",
        "##### Q6. In this dataset, do you need to use the Z-score Normalization? Explain.<br/>\n",
        "Ans- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J5J4I8XZYl3"
      },
      "source": [
        "### One-Hot Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBupCObXZYl4"
      },
      "source": [
        "\"temp\", \"atemp\",\"hum\" and \"windspeed\" are continuous values whereas the others contain discrete values. E.g. \"mnth\" can only take on the integers from 1 to 12. We need to perform one-hot encoding on discrete values for it to be processed in the model. One hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction.\n",
        "\n",
        "Perform one-hot encoding on all the categorical features and print the shape of your encoded array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7FH2iw6gTns",
        "outputId": "185e9541-d02b-4314-8165-d89a570af803",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_dataset['mnth'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS5NCI4rgm-e",
        "outputId": "43c970a4-8579-4e14-f309-199590ecfa86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_dataset.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2Uey8ZqjLGE",
        "outputId": "45447833-5db8-4757-93f4-082af43fdf2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "training_dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>season</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.4242</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.1940</td>\n",
              "      <td>283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.4848</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.4179</td>\n",
              "      <td>330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.5606</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.6364</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.1940</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.7424</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.1642</td>\n",
              "      <td>314</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   season  mnth  hr  holiday  weekday  ...  temp   atemp   hum  windspeed  cnt\n",
              "0       1    12  16        0        5  ...  0.42  0.4242  0.47     0.1940  283\n",
              "1       4    10   9        0        0  ...  0.50  0.4848  0.55     0.4179  330\n",
              "2       3     9   1        0        0  ...  0.62  0.5606  0.88     0.0000   88\n",
              "3       3     6  22        0        3  ...  0.70  0.6364  0.42     0.1940  183\n",
              "4       3     7  12        0        1  ...  0.80  0.7424  0.52     0.1642  314\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wal0J956ZYl5",
        "outputId": "45b88101-709a-43a8-a6c1-2c5d9d6a66d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "categorical_features = ['mnth',\n",
        "                        'season',\n",
        "                        'holiday',\n",
        "                        'weekday',\n",
        "                        'workingday',\n",
        "                        'weathersit']  \n",
        "\n",
        "# Transform\n",
        " \n",
        "onehot_encoder = OneHotEncoder()\n",
        "categorical_features_df = onehot_encoder.fit_transform(training_dataset[categorical_features])\n",
        "\n",
        "# Print the shape of your encoded X\n",
        "categorical_features_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qQsfdVCZYl-"
      },
      "source": [
        "##### Q7. What are the advantages and disadvantages of using One-hot encoding?<br/>\n",
        "Ans-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc1X2uKZZYl-"
      },
      "source": [
        "## Multiple Linear Regression\n",
        "\n",
        "In the big data era, it is highly unlikely that we are interested in the effect of a single variable on another. To simultaneously account for the effects of multiple variables, we use multiple regression (which accounts for the covariances between predictors).\n",
        "\n",
        "While the algorithmic solution to multiple regression exists, it is easier to conceptualize in terms of linear algebra. The optimal $\\hat{\\beta}$ vector that minimizes the residual sum of squares is:\n",
        "\n",
        "$\\hat{\\beta} = (X^TX)^{-1}X^Ty $\n",
        "\n",
        "\n",
        "Perform multiple linear regression on the training dataset, where the outcome is \"cnt\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XCyEPNOZYl_"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBokeqdcZYmC"
      },
      "source": [
        "# Bulding and fitting the Linear Regression model \n",
        "y_train = training_dataset['cnt']\n",
        "\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "regr.fit(X_train,y_train)\n",
        "\n",
        "y_pred = regr.predict(X_test)\n",
        "\n",
        "# Evaluating the Linear Regression model by computing MSE on training set\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "print('Mean squared error: %.2f'\n",
        "      % mean_squared_error(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByhuFThtZYmF"
      },
      "source": [
        "###### Q8. Print the value of bhat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKOF3Pg8ZYmF",
        "outputId": "d399cf81-ee8e-47b1-c24e-515ad9c7715b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHPPePFtZYmK"
      },
      "source": [
        "###### Q9. Is there a problem of multicolinearity? Explain what you can do<br/>\n",
        "Ans- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATGj71OfZYmL"
      },
      "source": [
        "### Goodness of fit\n",
        "\n",
        "A model can always make predictions. But it is important to determine how good the model is.\n",
        "How do we know that our model captures the data well? When evaluating model fit, a good metric is $R^2$, which corresponds to the amount of variance explained by the model. The formula for $R^2$ is the following:\n",
        "\n",
        "$R^2$ = $1 - \\dfrac{RSS}{TSS}$<br/>\n",
        "where:<br/>\n",
        "$RSS = \\Sigma(y - \\hat{y})^2$<br/>\n",
        "$TSS = \\Sigma(y - \\bar{y})^2$<br/>\n",
        "\n",
        "$R^2$ is also one metric for comparing models against each other. It is intuitive to say that the model that explains more variation in the data is a better fit than one that explains less variation. \n",
        "\n",
        "Fill in the code for calculation of R2 score "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M97LYtEqZYmM"
      },
      "source": [
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjKGIflyZYmR"
      },
      "source": [
        "#### R2 score for model with \"temp\" as predictor and \"cnt\" as outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM3P_lJEZYmT"
      },
      "source": [
        "# Print R2 score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print( r2_score(y_true, y_pred) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6_4FAVoZYmY"
      },
      "source": [
        "#### R2 score for model with \"temp\", \"hum\" as predictors and \"cnt\" as outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvGmnqqPZYmY"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Print R2 score\n",
        "print( r2_score(y_true, y_pred) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnNaQ4GmZYmb"
      },
      "source": [
        "#### R2 score for model with  \"temp\", \"atemp\", \"hum\" as predictors and \"cnt\" as outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmZ8fKghZYmc"
      },
      "source": [
        "\n",
        "\n",
        "# Print R2 score\n",
        "print( r2_score(y_true, y_pred) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU3QTI_2ZYmg"
      },
      "source": [
        "You can see $R^2$ is always going up as we keep adding features.\n",
        "\n",
        "This is one drawback of only using $R^2$ to evaluate your model. Adding predictors will always improve the predictive ability of your model, though it may not be meaningful.\n",
        "\n",
        "That is to say, we are not necessarily interested in making a perfect prediciton of our data. If we were, we would always use all of the predictors available. Rather, we are interested in the most predictive features, in the hopes that we can create a simpler model that performs nearly as well.\n",
        "\n",
        "This is why we consider another metric, Adjusted R2.\n",
        "The adjusted R-squared increases only if the new term improves the model more than would be expected by chance.\n",
        "Using Adjusted R2 score, please give the most relevant combination of predictors in determining the profit of the startup.\n",
        "\n",
        "\n",
        "$AdjustedR^2$ = $1 - \\dfrac{(1-R^2)(n-1)}{(n-k-1)}$<br/>\n",
        "where:<br/>\n",
        "n = number of samples<br/>\n",
        "k = number of features\n",
        "\n",
        "Fill in the code for calculation of adjusted R2 score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GucRvGA4ZYmh"
      },
      "source": [
        "#### Adjusted R2 score for model with \"temp\" as predictor and \"cnt\" as outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD6M2tpRZYmh"
      },
      "source": [
        "\n",
        "\n",
        "# Print Adjusted R2 score\n",
        "def adjusted_R_squared(n, k, y_true,y_pred ): \n",
        "  adjusted_R_squared = 1- (1- (r2_score(y_true, y_pred))**2)*(n-1)/(n-k-1)\n",
        "  return(adjusted_R_squared )\n",
        "\n",
        "\n",
        "adjusted_R_squared(n=  , k =  , y_true=  ,y_pred = )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWyLvmE_ZYml"
      },
      "source": [
        "#### Adjusted R2 score for model with \"temp\", \"hum\" as predictors and \"cnt\" as outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OlvfiHnZYmm"
      },
      "source": [
        "\n",
        "\n",
        "# Print Adjusted R2 score\n",
        "adjusted_R_squared(n=  , k =  , y_true=  ,y_pred = )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-IMp_hKZYmp"
      },
      "source": [
        "#### Adjusted R2 score for model with  \"temp\", \"atemp\", \"hum\" as predictors and \"cnt\" as outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV10Y7pRZYmq"
      },
      "source": [
        "\n",
        "\n",
        "# Print Adjusted R2 score\n",
        "adjusted_R_squared(n=  , k =  , y_true=  ,y_pred = )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYStRl0oZYms"
      },
      "source": [
        "### K-fold Cross-Validation\n",
        "\n",
        "However, adjusted R2 is not enough to help us ahieve the best model, a more robust method is k-fold cross-validation.\n",
        "\n",
        "* Randomly split dataset into K equal-sized subsets, or folds\n",
        "* Treat each fold as validation set (train on all but K'th fold and test on K'th fold only)\n",
        "\n",
        "* The overall error is then the mean error over all K models.\n",
        "* Most common are 5- or 10-fold cross-validation\n",
        "\n",
        "Please implement a 5-fold cross-validation by yourselves to find the best model in terms of Mean Square Error(MSE)\n",
        "\n",
        "**Do not use sklearn.model_selection.cross_val_score or other built-in cross-validaiton functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y95vfteCZYms"
      },
      "source": [
        "# Design a function to implement 5-fold cross-validation. \n",
        "# The input: training features X, training target y.\n",
        "# The output: the average of MSE over the 5 folds.\n",
        "\n",
        "def cross_val_mse(X, y):\n",
        "    # Write your code here\n",
        "    \n",
        "    \n",
        "    # sample the data \n",
        "\n",
        "    # build model\n",
        "\n",
        "    # predict \n",
        "\n",
        "    # store the error \n",
        "\n",
        "    # mean error \n",
        "\n",
        "\n",
        "    return()\n",
        "\n",
        "# By using your above function, find the best combination of features, which has the lowest averaged MSE\n",
        "cross_val_mse(X, y)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRP4XvUvZYmw"
      },
      "source": [
        "# Print the best features \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhp6_wW9ZYmy"
      },
      "source": [
        "### Test your model\n",
        "Now, apply your best model to predict the target values from the test feature set \"BikeSharing_Xtest.csv\". We will grade this part based on your prediction error.\n",
        "\n",
        "Hint: Please be careful on standardization and one-hot encoding (if you use), the test set should be consistent with the training set in terms of any transformation.\n",
        "\n",
        "Hint2: You may want to modify the previous steps to make the transformation of the test set consistent with the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMNUGShgZYmz"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# If use standardization and one-hot we need to apply them to the testing as well.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Output your prediction on test set as y_pred. It should be a 200 x 1 vector.\n",
        "# y_pred ="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwjPgS3wZYm5"
      },
      "source": [
        "#end"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}